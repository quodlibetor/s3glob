//! A pattern is a glob that knows how to split itself into a prefix and join with a partial prefix

use std::collections::BTreeSet;
use std::sync::Arc;

use anyhow::{Context as _, Result, bail};
use glob::Glob;
use globset::GlobMatcher;
use itertools::Itertools as _;
use regex::Regex;
use tokio::sync::Semaphore;
use tracing::{debug, trace, warn};

mod engine;
pub use engine::{Engine, S3Engine};

use crate::{progress, progressln};

mod glob;

pub(crate) const GLOB_CHARS: &[char] = &['*', '?', '[', '{'];

/// The maximum number of prefixes that can be generated by the glob matcher
///
/// Checking that constructed prefixes exist is significantly slower than
/// scanning for objects.
const MAX_PREFIXES: usize = 100_000;

const MAX_CHECK_PREFIXES: usize = 10_000;

/// Parallelism is determined by the number of prefixes, and 50 is much faster
/// than 1
const DESIRED_MIN_PREFIXES: usize = 25;

/// A thing that knows how to generate and filter S3 prefixes based on a glob pattern
#[derive(Debug, Clone)]
pub struct S3GlobMatcher {
    raw: String,
    delimiter: char,
    parts: Vec<glob::Glob>,
    glob: GlobMatcher,
    max_parallelism: usize,
    min_prefixes: usize,
    /// True if no further listing needs to be done by the caller
    ///
    /// Generally anything that does not contain a ** will be complete
    is_complete: bool,
}

#[derive(Debug)]
pub(crate) struct PrefixSearchResult {
    pub prefixes: Vec<String>,
    pub max_prefixes_observed: usize,
    pub max_objects_observed: usize,
}

/// A scanner takes a glob pattern and can efficiently generate a list of S3
/// prefixes based on it.
impl S3GlobMatcher {
    pub fn parse(raw: String, delimiter: &str) -> Result<Self> {
        let mut parts = Vec::new();
        let mut remaining = &*raw;
        while !remaining.is_empty() {
            let next_idx = remaining.find(GLOB_CHARS);
            match next_idx {
                Some(idx) => {
                    let next_part = remaining[..idx].to_string();
                    if !next_part.is_empty() {
                        parts.push(glob::Glob::Choice {
                            raw: next_part.clone(),
                            allowed: vec![next_part.clone()],
                        });
                    }
                    let gl = glob::parse_pattern(&remaining[idx..]).context("Parsing pattern")?;
                    remaining = &remaining[idx + gl.pattern_len()..];
                    parts.push(gl);
                }
                None => {
                    parts.push(glob::Glob::Choice {
                        raw: remaining.to_string(),
                        allowed: vec![remaining.to_string()],
                    });
                    break;
                }
            }
        }

        let mut new_parts: Vec<glob::Glob> = Vec::new();
        for part in parts {
            if let Some(last) = new_parts.last_mut() {
                if last.is_choice() && part.is_choice() {
                    last.combine_with(&part);
                } else {
                    new_parts.push(part);
                }
            } else {
                new_parts.push(part);
            }
        }
        if new_parts.last().is_some_and(|p| p.ends_with(delimiter)) {
            new_parts.push(glob::Glob::SyntheticAny);
        }

        debug!(pattern = %raw, parsed = ?new_parts, "parsed pattern");
        let glob = globset::Glob::new(&raw)?;
        let is_complete = new_parts.iter().all(|p| !p.is_recursive());

        Ok(S3GlobMatcher {
            raw,
            delimiter: delimiter.chars().next().unwrap(),
            parts: new_parts,
            glob: glob.compile_matcher(),
            max_parallelism: 500,
            min_prefixes: DESIRED_MIN_PREFIXES,
            is_complete,
        })
    }

    // TODO: this should be a constructor argument, but I don't want to change
    // all the tests right now
    pub fn set_max_parallelism(&mut self, max_parallelism: usize) {
        self.max_parallelism = max_parallelism;
    }

    /// Find all S3 prefixes that could match this pattern
    ///
    /// This method works by incrementally building up prefixes and filtering them based on
    /// the pattern parts:
    ///
    /// - For literal parts, it appends them to existing prefixes and queries S3 for matches
    /// - For pattern parts:
    ///   - `*` matches everything, but continues prefix generation
    ///   - `{a,b}` or `[ab]` either filters existing prefixes or generates new ones by appending each alternative
    ///   - `**` stops prefix generation (since it matches any number of path components)
    ///
    /// # Returns
    ///
    /// A list of S3 prefixes that could contain matches for this pattern
    ///
    /// # Example
    ///
    /// For pattern "foo/{bar,baz}*jook/qux*{alpha,beta}/**":
    /// 1. Start with [""]
    /// 2. Append "foo/" -> ["foo/"]
    /// 3. Append alternatives -> ["foo/bar", "foo/baz"]
    /// 4. Search for all folders in ["foo/bar", "foo/baz"]
    /// 4. Append "qux" -> ["foo/bar/qux", "foo/baz/qux"]
    /// 5. Filter by "*" -> keep prefixes whose last component starts with "qux"
    pub async fn find_prefixes(
        &self,
        mut engine: impl Engine + Clone,
    ) -> Result<PrefixSearchResult> {
        debug!("finding prefixes for {}", self.raw);
        let mut prefixes = BTreeSet::new();
        prefixes.insert("".to_string());
        let delimiter = self.delimiter.to_string();
        let mut regex_so_far = "^".to_string();
        let mut prev_part = None;
        let mut part_iter = self.parts.iter().enumerate();
        let mut max_prefixes_observed = 0;
        let mut max_objects_observed = 0;
        for (part_idx, part) in &mut part_iter {
            if prefixes.len() >= MAX_PREFIXES {
                warn!(
                    new_prefix_count = prefixes.len(),
                    "We have over {MAX_PREFIXES} prefixes, stopping prefix generation"
                );
                break;
            }
            max_prefixes_observed = max_prefixes_observed.max(prefixes.len());
            // only included prefixes in trace logs
            trace!(?prefixes, "scanning for part");
            debug!(%regex_so_far, new_part = %part.re_string(&delimiter), prefix_count = prefixes.len(), "scanning for part");
            if tracing::enabled!(tracing::Level::DEBUG) {
                // don't overwrite log messages
                progressln!("Discovering prefixes: {:>6}", prefixes.len());
            } else {
                progress!("\rDiscovering prefixes: {:>6}", prefixes.len());
            }
            // We always want to scan for things including the last part,
            // finding more prefixes in it is guaranteed to be slower than
            // just searching because we have to do an api call to check each
            // prefix, instead of allowing aws to list them for us.
            match part {
                glob::Glob::Recursive => {
                    // we can also skip the last part if it's not a negated character class
                    debug!("found recursive glob, stopping prefix generation");
                    break;
                }
                // Any is the only place where we actually need to hit the
                // engine to scan for prefixes, everything else is either a
                // literal append or a regex filter
                glob::Glob::Any { .. } | glob::Glob::SyntheticAny => {
                    // never scan if the previous part was an any, because the last scan will have
                    // already found all of the prefixes that match the any
                    let scan_might_help = !matches!(prev_part, Some(&Glob::Any { .. }));
                    if scan_might_help {
                        debug!(part = %part.display(), "scanning for keys in an Any");
                        let (tx, mut rx) = tokio::sync::mpsc::channel(prefixes.len());

                        let mut tasks = Vec::new();
                        let semaphore = Arc::new(Semaphore::new(self.max_parallelism));
                        for prefix in &prefixes {
                            let client_prefix = prefix.clone();
                            let delimiter = delimiter.clone();
                            let tx = tx.clone();
                            let permit = semaphore.clone().acquire_owned().await;
                            let mut engine = engine.clone();
                            let prefix = prefix.clone();

                            let task = tokio::spawn(async move {
                                match engine.scan_prefixes(&client_prefix, &delimiter).await {
                                    Ok(results) => {
                                        let _ = tx.send(Ok((prefix, results))).await;
                                    }
                                    Err(e) => {
                                        let _ = tx.send(Err(e)).await;
                                    }
                                }
                                drop(permit);
                            });
                            tasks.push(task);
                        }

                        drop(tx);

                        let mut new_prefixes = BTreeSet::new();
                        let mut new_prefix_count = 0;
                        while let Some(result) = rx.recv().await {
                            let (scanned_prefix, results) = result.context("scanning prefixes")?;
                            let result_len = results.len();
                            trace!(
                                scanned_prefix,
                                scanned_results_count = result_len,
                                scanned_results = ?results,
                                "Scanning for any, got result from task"
                            );
                            new_prefixes.extend(results);
                            new_prefix_count = new_prefixes.len();
                            if new_prefix_count >= MAX_PREFIXES {
                                debug!(
                                    new_prefix_count,
                                    "Scanning for any, found more than {MAX_PREFIXES} prefixes, aborting"
                                );
                                for task in tasks {
                                    task.abort();
                                }
                                break;
                            }
                        }
                        // don't overwrite if we gave up early, we'll break at the top of the loop
                        if new_prefix_count < MAX_PREFIXES {
                            prefixes = new_prefixes;
                        }
                    }
                    max_objects_observed = max_objects_observed.max(prefixes.len());
                    if part.is_negated() {
                        // if this part is a negated character class then we should filter
                        let matcher = Regex::new(&format!(
                            "{regex_so_far}{}",
                            part.re_string(&self.delimiter.to_string())
                        ))
                        .unwrap();
                        debug!(regex = %matcher.as_str(), "filtering for negated Any");
                        prefixes.retain(|p| matcher.is_match(p));
                    }
                }
                glob::Glob::Choice { allowed, .. } => {
                    // In an alternation we need to check for two cases:
                    // - we are verifying that the middle of the path matches
                    //   one of the alternatives -- this is just a regex filter
                    //
                    //   This happens when the previous part does _not_
                    //   with the delimiter.
                    //
                    // - we are constructing a new path component from the list of alternaives,
                    //   where we just join each alternative with the
                    //   delimiter.
                    //
                    //   This happens when the previous part ended with
                    //   the delimiter, or the pattern starts with an
                    //   alternation

                    // if there is no previous part
                    let is_simple_append = part_idx == 0;

                    if is_simple_append {
                        debug!(allowed = %allowed.join(","), "simple append");
                        let mut new_prefixes = BTreeSet::new();
                        for prefix in &prefixes {
                            for alt in allowed {
                                new_prefixes.insert(prefix_join(prefix, alt));
                            }
                        }
                        if new_prefixes.len() >= MAX_CHECK_PREFIXES {
                            debug!(
                                new_prefix_count = new_prefixes.len(),
                                "simple append generated over {MAX_CHECK_PREFIXES} prefixes, using prefixes from previous part"
                            );
                            break;
                        }
                        max_objects_observed = max_objects_observed.max(new_prefixes.len());
                        prefixes = check_prefixes(
                            &mut engine,
                            &prefixes,
                            new_prefixes,
                            self.max_parallelism,
                        )
                        .await?;
                    } else {
                        // Build up the filters and appends
                        let mut filters = BTreeSet::new();
                        let mut appends = BTreeSet::new();
                        for choice in allowed {
                            // the last part is guaranteed to be an Any,
                            if choice.starts_with(self.delimiter) {
                                let c = choice.chars().skip(1).collect::<String>();
                                if !c.is_empty() {
                                    appends.insert(c);
                                }
                                filters.insert(self.delimiter.to_string());
                            } else if choice.contains(self.delimiter) {
                                let up_to_delim = choice
                                    .chars()
                                    .take_while_inclusive(|c| *c != self.delimiter)
                                    .collect::<String>();
                                filters.insert(regex::escape(&up_to_delim));

                                let after_delim = choice[up_to_delim.len()..].to_string();
                                if !after_delim.is_empty() {
                                    appends.insert(after_delim);
                                }
                            } else {
                                filters.insert(regex::escape(choice));
                            }
                        }

                        let filter = if filters.is_empty() {
                            Regex::new(&regex_so_far).unwrap()
                        } else if filters.len() == 1 {
                            Regex::new(&format!(
                                "{}{}",
                                regex_so_far,
                                filters.iter().next().unwrap()
                            ))
                            .unwrap()
                        } else {
                            let filters = filters.iter().join("|");
                            Regex::new(&format!("{}({})", regex_so_far.as_str(), filters)).unwrap()
                        };
                        let append_matcher =
                            Regex::new(&format!("{}{}", regex_so_far, part.re_string(&delimiter)))
                                .unwrap();
                        trace!(
                            ?filters, ?appends, filter_regex = %filter.as_str(), append_regex = %append_matcher.as_str(), ?prefixes,
                            "filtering and appending to prefixes",
                        );

                        let new_prefixes = if filters.is_empty() {
                            debug!("no filters, appending");
                            let mut new_prefixes = BTreeSet::new();
                            for prefix in &prefixes {
                                for alt in &appends {
                                    new_prefixes.insert(prefix_join(prefix, alt));
                                }
                            }
                            new_prefixes
                        } else if appends.is_empty() {
                            debug!("no appends, filtering");
                            let mut new_prefixes = BTreeSet::new();
                            for prefix in &prefixes {
                                if filter.is_match(prefix) {
                                    new_prefixes.insert(prefix.clone());
                                }
                            }
                            new_prefixes
                        } else {
                            debug!("filtering and appending");
                            let mut new_prefixes = BTreeSet::new();
                            for prefix in &prefixes {
                                if filter.is_match(prefix) {
                                    // we only need to add alts if it's not already matched
                                    if append_matcher.is_match(prefix) {
                                        new_prefixes.insert(prefix.clone());
                                    } else {
                                        for alt in &appends {
                                            new_prefixes.insert(prefix_join(prefix, alt));
                                        }
                                    }
                                }
                            }
                            trace!(?new_prefixes, "filtered and appended prefixes");
                            new_prefixes
                        };

                        if !appends.is_empty() {
                            if new_prefixes.len() >= MAX_PREFIXES {
                                // checking prefixes is significantly slower
                                // than scanning existing prefixes.
                                debug!(
                                    new_prefix_count = new_prefixes.len(),
                                    "Appends generated over {MAX_PREFIXES} prefixes, using prefixes from previous part"
                                );
                                break;
                            }
                            trace!(new_prefixes = ?new_prefixes, new_prefix_count = new_prefixes.len(), "checking appended prefixes");
                            max_objects_observed = max_objects_observed.max(new_prefixes.len());
                            prefixes = check_prefixes(
                                &mut engine,
                                &prefixes,
                                new_prefixes,
                                self.max_parallelism,
                            )
                            .await?;
                        } else if !new_prefixes.is_empty() {
                            debug!("no appends, using new prefixes");
                            prefixes = new_prefixes;
                        } else {
                            let glob_so_far = self
                                .parts
                                .iter()
                                .take(part_idx + 1)
                                .map(|p| p.raw())
                                .join("");
                            let max_prefixes = if tracing::enabled!(tracing::Level::DEBUG) {
                                usize::MAX
                            } else {
                                20
                            };
                            let and_more = if prefixes.len() > max_prefixes {
                                format!(
                                    "\n  ...and {} more (run with --verbose to see all)",
                                    prefixes.len() - max_prefixes
                                )
                            } else {
                                String::new()
                            };

                            bail!(
                                "Could not continue search in prefixes:\n  {}{}\
                                \n\n\
                                None of the above matched the pattern:\n  {glob_so_far}",
                                prefixes.iter().take(max_prefixes).join("\n  "),
                                and_more,
                            );
                        }
                    }
                }
            }

            // clean up state-tracking
            regex_so_far = format!(
                "{}{}",
                regex_so_far.as_str(),
                part.re_string(&self.delimiter.to_string())
            );

            prev_part = Some(part);
        }

        if prefixes.len() < self.min_prefixes && !self.is_complete {
            let count = prefixes.len();
            progressln!(
                "\rDiscovered prefixes: {count:>5} -- see `s3glob help parallelism` if it feels like this run is too slow"
            );
        } else if self.is_complete {
            // clear the previous output
            progressln!(
                "\r                                          \
                 \rDiscovered matches: {:>5}",
                prefixes.len()
            );
        } else {
            // clear the previous output
            progressln!(
                "\r                                          \
                 \rDiscovered prefixes: {:>5}",
                prefixes.len()
            );
        }
        Ok(PrefixSearchResult {
            prefixes: prefixes.into_iter().collect(),
            max_prefixes_observed,
            max_objects_observed,
        })
    }

    /// True if no further listing needs to be done by the caller
    pub fn is_complete(&self) -> bool {
        self.is_complete
    }

    pub fn is_match(&self, path: &str) -> bool {
        self.glob.is_match(path)
    }

    #[cfg(test)]
    fn set_min_prefixes(&mut self, min_prefixes: usize) {
        self.min_prefixes = min_prefixes;
    }
}

async fn check_prefixes(
    engine: &mut (impl Engine + Clone),
    prefixes: &BTreeSet<String>,
    new_prefixes: BTreeSet<String>,
    max_parallelism: usize,
) -> Result<BTreeSet<String>, anyhow::Error> {
    if prefixes.is_empty() || new_prefixes.is_empty() {
        bail!("Surprisingly, no prefixes to build off of and no prefixes found");
    }
    let checked_prefixes = engine
        .check_prefixes(new_prefixes.clone(), max_parallelism)
        .await?;
    if checked_prefixes.is_empty() {
        let mut message = vec!["Searched for prefixes do not exist in the bucket:".to_string()];
        let new_prefixes = new_prefixes.iter().collect::<Vec<_>>();
        let mut new_idx = 0;
        for prefix in prefixes {
            message.push(format!("  {}", prefix));
            let mut new_prefix = new_prefixes.get(new_idx);
            while new_prefix.is_some()
                && &prefix <= new_prefix.unwrap()
                && new_prefix.unwrap().starts_with(prefix)
            {
                message.push(format!(
                    "    INVALID: {}",
                    &new_prefixes[new_idx][prefix.len()..]
                ));
                new_idx += 1;
                new_prefix = new_prefixes.get(new_idx);
            }
        }

        bail!("{}", message.join("\n"));
    }
    Ok(checked_prefixes)
}

fn prefix_join(prefix: &str, alt: &str) -> String {
    format!("{prefix}{alt}")
}

#[cfg(test)]
mod tests {
    use assert2::{assert, check};

    use super::*;
    use crate::glob_matcher::engine::MockS3Engine;
    use crate::{assert_scanner_part, setup_logging};
    use tracing::info;

    //
    // find_prefixes tests
    //

    #[tokio::test]
    async fn test_find_prefixes_literal() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("src/foo/bar".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        let engine = MockS3Engine::new(vec!["src/foo/bar".to_string()]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["src/foo/bar"]);
        let e: &[(&str, &str)] = &[];
        engine.assert_calls(e);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_alternation_no_any() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("src/{foo,bar}/baz".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        let engine = MockS3Engine::new(vec![
            "src/foo/baz".to_string(),
            "src/bar/baz".to_string(),
            "src/qux/baz".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["src/bar/baz", "src/foo/baz"]);
        let e: &[(&str, &str)] = &[];
        engine.assert_calls(e);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_alternation_with_any() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("src/{foo,bar}*/baz".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        println!("scanner_parts for {}:\n{:?}", scanner.raw, scanner.parts);
        let engine = MockS3Engine::new(vec![
            "src/foo/baz".to_string(),
            "src/bar/baz".to_string(),
            "src/foo-quux/baz".to_string(),
            "src/qux/baz".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        engine.assert_calls(&[("src/bar", "/"), ("src/foo", "/")]);
        assert!(prefixes == vec!["src/bar/baz", "src/foo-quux/baz", "src/foo/baz"]);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_star() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("src/*/main.rs".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        let engine = MockS3Engine::new(vec![
            "src/foo/main.rs".to_string(),
            "src/bar/main.rs".to_string(),
            "src/baz/other.rs".to_string(),
        ]);
        info!(?engine.paths);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["src/bar/main.rs", "src/foo/main.rs"]);
        engine.assert_calls(&[("src/", "/")]);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_recursive() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("src/**/test.rs".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        let engine = MockS3Engine::new(vec![
            "src/test.rs".to_string(),
            "src/foo/test.rs".to_string(),
            "src/foo/bar/test.rs".to_string(),
            "src/other.rs".to_string(),
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        // Should stop at src/ since ** matches anything after
        assert!(prefixes == vec!["src/"]);
        let e: &[(&str, &str)] = &[];
        engine.assert_calls(e);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_character_class() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("src/[abc]*/zebra.rs".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        assert_scanner_part!(&scanner.parts[0], Choice(vec!["src/a", "src/b", "src/c"]));
        assert_scanner_part!(&scanner.parts[1], Any("*"));
        assert_scanner_part!(&scanner.parts[2], OneChoice("/zebra.rs"));
        let engine = MockS3Engine::new(vec![
            "src/abc/zebra.rs".to_string(),
            "src/baz/zebra.rs".to_string(),
            "src/cat/zebra.rs".to_string(),
            "src/dog/zebra.rs".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        engine.assert_calls(&[("src/a", "/"), ("src/b", "/"), ("src/c", "/")]);
        assert!(prefixes == vec!["src/abc/zebra.rs", "src/baz/zebra.rs", "src/cat/zebra.rs"]);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_alternation_then_any() -> Result<()> {
        let mut scanner = S3GlobMatcher::parse("literal/{foo,bar}*/baz".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        println!("scanner_parts for {}:\n{:#?}", scanner.raw, scanner.parts);

        assert_scanner_part!(
            &scanner.parts[0],
            Choice(vec!["literal/foo", "literal/bar"])
        );
        assert_scanner_part!(&scanner.parts[1], Any("*"));
        assert_scanner_part!(&scanner.parts[2], OneChoice("/baz"));

        let engine = MockS3Engine::new(vec![
            "literal/bar-stuff/baz".to_string(),
            "literal/foo-extra/baz".to_string(),
            "literal/foo/baz".to_string(),
            "literal/other/baz".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        engine.assert_calls(&[("literal/bar", "/"), ("literal/foo", "/")]);
        assert!(
            prefixes
                == vec![
                    "literal/bar-stuff/baz",
                    "literal/foo-extra/baz",
                    "literal/foo/baz",
                ]
        );
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_alternation_any_literal() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("literal/{foo,bar}*quux/baz".to_string(), "/")?;
        scanner.set_min_prefixes(0);

        assert_scanner_part!(
            &scanner.parts[0],
            Choice(vec!["literal/foo", "literal/bar"])
        );
        assert_scanner_part!(&scanner.parts[1], Any("*"));
        assert_scanner_part!(&scanner.parts[2], OneChoice("quux/baz"));

        let engine = MockS3Engine::new(vec![
            "literal/foo-quux/baz".to_string(),
            "literal/bar-quux/baz".to_string(),
            // Should be filtered out
            "literal/foo-something-bar/baz".to_string(),
            "literal/other-quux/baz".to_string(),
            "literal/foo-quux-bar/baz".to_string(),
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["literal/bar-quux/baz", "literal/foo-quux/baz"]);
        engine.assert_calls(&[("literal/bar", "/"), ("literal/foo", "/")]);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_any_then_alternation() -> Result<()> {
        let mut scanner = S3GlobMatcher::parse("literal/*{foo,bar}/baz".to_string(), "/")?;
        scanner.set_min_prefixes(0);

        assert_scanner_part!(&scanner.parts[0], OneChoice("literal/"));
        assert_scanner_part!(&scanner.parts[1], Any("*"));
        assert_scanner_part!(&scanner.parts[2], Choice(vec!["foo/baz", "bar/baz"]));

        let engine = MockS3Engine::new(vec![
            "literal/something-foo/baz".to_string(),
            "literal/other-bar/baz".to_string(),
            "literal/not-match/baz".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        engine.assert_calls(&[("literal/", "/")]);
        assert!(prefixes == vec!["literal/other-bar/baz", "literal/something-foo/baz"]);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_literal_any_alternation() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("literal/quux*{foo,bar}/baz".to_string(), "/")?;
        scanner.set_min_prefixes(0);

        assert_scanner_part!(&scanner.parts[0], OneChoice("literal/quux"));
        assert_scanner_part!(&scanner.parts[1], Any("*"));
        assert_scanner_part!(&scanner.parts[2], Choice(vec!["foo/baz", "bar/baz"]));

        let engine = MockS3Engine::new(vec![
            "literal/quux-foo/baz".to_string(),
            "literal/quux-something-bar/baz".to_string(),
            "literal/quux-other/baz".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        engine.assert_calls(&[("literal/quux", "/")]);
        assert!(prefixes == vec!["literal/quux-foo/baz", "literal/quux-something-bar/baz"]);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_any_after_last_delimiter() -> Result<()> {
        let mut scanner = S3GlobMatcher::parse("literal/baz*/a.rs".to_string(), "/")?;
        scanner.set_min_prefixes(0);

        assert_scanner_part!(&scanner.parts[0], OneChoice("literal/baz"));
        assert_scanner_part!(&scanner.parts[1], Any("*"));
        assert_scanner_part!(&scanner.parts[2], OneChoice("/a.rs"));

        let engine = MockS3Engine::new(vec![
            "literal/baz/a.rs".to_string(),
            "literal/baz-extra/a.rs".to_string(),
            "literal/bazinga/a.rs".to_string(),
            "literal/other/a.rs".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        engine.assert_calls(&[("literal/baz", "/")]);
        assert!(
            prefixes
                == vec![
                    "literal/baz-extra/a.rs",
                    "literal/baz/a.rs",
                    "literal/bazinga/a.rs"
                ]
        );
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_any_and_character_class() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("literal/baz*[ab]/1.rs".to_string(), "/")?;
        scanner.set_min_prefixes(0);

        assert_scanner_part!(&scanner.parts[0], OneChoice("literal/baz"));
        assert_scanner_part!(&scanner.parts[1], Any("*"));
        assert_scanner_part!(&scanner.parts[2], Choice(vec!["a/1.rs", "b/1.rs"]));

        let engine = MockS3Engine::new(vec![
            "literal/baz-a/1.rs".to_string(),
            "literal/baz-extra-b/1.rs".to_string(),
            "literal/baz-c/1.rs".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        engine.assert_calls(&[("literal/baz", "/")]);
        assert!(prefixes == vec!["literal/baz-a/1.rs", "literal/baz-extra-b/1.rs"]);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_empty_alternative() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("src/{,tmp}/file".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        let engine = MockS3Engine::new(vec![
            "src/file".to_string(),
            "src/tmp/file".to_string(),
            "src/other/file".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["src/tmp/file"]);
        let e: &[(&str, &str)] = &[];
        engine.assert_calls(e);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_empty_alternative_with_delimiter() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("src/{,tmp/}file".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        let engine = MockS3Engine::new(vec![
            "src/file".to_string(),
            "src/tmp/file".to_string(),
            "src/other/file".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["src/file", "src/tmp/file"]);
        let e: &[(&str, &str)] = &[];
        engine.assert_calls(e);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_alternation_with_delimiter() -> Result<()> {
        let mut scanner = S3GlobMatcher::parse("src/{foo/bar,baz}/test".to_string(), "/")?;
        scanner.set_min_prefixes(0);

        assert_scanner_part!(
            &scanner.parts[0],
            Choice(vec!["src/foo/bar/test", "src/baz/test"])
        );

        let engine = MockS3Engine::new(vec![
            "src/foo/bar/test".to_string(),
            "src/baz/test".to_string(),
            "src/foo/test".to_string(),     // Should be filtered out
            "src/foo/baz/test".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["src/baz/test", "src/foo/bar/test"]);
        let e: &[(&str, &str)] = &[]; // No API calls needed since alternation is static
        engine.assert_calls(e);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_negative_class_start() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("[!a]*/foo".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        let engine = MockS3Engine::new(vec![
            "b/foo".to_string(),
            "c/foo".to_string(),
            "xyz/foo".to_string(),
            "a/foo".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["b/foo", "c/foo", "xyz/foo"]);
        engine.assert_calls(&[("", "/")]);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_negative_class_after_wildcard() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("*[!f]oo/*".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        let engine = MockS3Engine::new(vec![
            "zoo/a".to_string(),
            "boo/a".to_string(),
            "foo/a".to_string(),           // Should be filtered out
            "something/foo/a".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["boo/a", "zoo/a"]);
        // TODO: this could be improved to only call the engine once
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_negative_class_between_alternations() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("{foo,bar}[!z]*/baz".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        let engine = MockS3Engine::new(vec![
            "foo-abc/baz".to_string(),
            "bar-def/baz".to_string(),
            "fooz/baz".to_string(),  // Should be filtered out
            "barz/baz".to_string(),  // Should be filtered out
            "other/baz".to_string(), // Should be filtered out
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["bar-def/baz", "foo-abc/baz"]);
        engine.assert_calls(&[("bar", "/"), ("foo", "/")]);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_multiple_negative_classes() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("[!a]*[!b]/foo".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        let engine = MockS3Engine::new(vec![
            "c-x/foo".to_string(),
            "d-y/foo".to_string(),
            // filtered out
            "a-b/foo".to_string(), // (both conditions fail)
            "a-x/foo".to_string(), // (first char is a)
            "c-b/foo".to_string(), // (second part starts with b)
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["c-x/foo", "d-y/foo"]);
        engine.assert_calls(&[("", "/")]);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_negative_class_with_delimiter() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("foo/[!/]/bar".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        assert_scanner_part!(&scanner.parts[0], OneChoice("foo/"));
        assert_scanner_part!(&scanner.parts[1], Any("[!/]"));
        assert_scanner_part!(&scanner.parts[2], OneChoice("/bar"));

        let engine = MockS3Engine::new(vec![
            "foo/x/bar".to_string(),
            "foo/a/bar".to_string(),
            "foo//bar".to_string(),    // Should be filtered out
            "foo/a/b/bar".to_string(), // Should be filtered out (too many segments)
            "foo///bar".to_string(),   // Should be filtered out (the excluded char)
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["foo/a/bar", "foo/x/bar"]);
        engine.assert_calls(&[("foo/", "/")]);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_complex_negative_pattern() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("*{foo,bar}*[!Z]/baz".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        let engine = MockS3Engine::new(vec![
            "x-foo-a/baz".to_string(),
            "y-bar-b/baz".to_string(),
            // filtered out
            "x-foo-Z/baz".to_string(), // (ends with Z)
            "y-bar-Z/baz".to_string(), // (ends with Z)
            "x-baz-a/baz".to_string(), // (middle not foo/bar)
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["x-foo-a/baz", "y-bar-b/baz"]);
        // TODO: this could be improved to only call the engine once
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_file_any_then_constant() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("src/*/*zebra".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        let engine = MockS3Engine::new(vec![
            "src/foo/1_zebra".to_string(),
            "src/bar/2_zebra".to_string(),
            "src/baz/3_zebra".to_string(),
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["src/bar/2_zebra", "src/baz/3_zebra", "src/foo/1_zebra"]);
        Ok(())
    }

    #[tokio::test]
    async fn test_find_prefixes_sep_const_file_any_constant() -> Result<()> {
        setup_logging(Some("s3glob=trace"));
        let mut scanner = S3GlobMatcher::parse("src/*/1*zebra".to_string(), "/")?;
        scanner.set_min_prefixes(0);
        let engine = MockS3Engine::new(vec![
            "src/foo/1_zebra".to_string(),
            "src/bar/2_zebra".to_string(),
            "src/baz/3_zebra".to_string(),
        ]);

        let prefixes = scanner.find_prefixes(engine.clone()).await?.prefixes;
        assert!(prefixes == vec!["src/foo/1_zebra"]);
        assert!(scanner.is_complete());
        Ok(())
    }

    //
    // Helpers
    //

    #[macro_export]
    macro_rules! assert_scanner_part {
        // Helper rule for match testing
        (@test_matches, $re:expr, $expected_matches:expr, !$expected_does_not_match:expr) => {
            for m in $expected_matches {
                assert!($re.is_match(m), "Regex {} failed to match {m:?}", $re.as_str());
            }
            for m in $expected_does_not_match {
                assert!(!$re.is_match(m), "Regex {} unexpectedly matched {m:?}", $re.as_str());
            }
        };

        ($part:expr, Any($expected:expr), $expected_matches:expr, !$expected_does_not_match:expr) => {
            match $part {
                Glob::Any { raw, .. } => {
                    assert!(*raw == $expected);
                    assert_scanner_part!(@test_matches, $part.re("/"), $expected_matches, !$expected_does_not_match);
                }
                other => panic!("Expected Any({:?}), got {:?}", $expected, other),
            }
        };
        ($part:expr, SyntheticAny) => {
            match $part {
                Glob::SyntheticAny => {}
                other => panic!("Expected SyntheticAny, got {:?}", other),
            }
        };
        ($part:expr, Any($expected:expr)) => {{
            let em: &[&str] = &[];
            let ednm: &[&str] = &[];
            assert_scanner_part!($part, Any($expected), em, !ednm);
        }};

        ($part:expr, NegatedAny($expected:expr), $expected_matches:expr, !$expected_does_not_match:expr) => {
            match $part {
                Glob::Any { raw } => {
                    assert!(*raw == $expected);
                    assert_scanner_part!(@test_matches, $part.re("/"), $expected_matches, !$expected_does_not_match);
                }
                other => panic!("Expected Any({:?}), got {:?}", $expected, other),
            }
        };
        ($part:expr, Recursive, $expected_matches:expr) => {
            match $part {
                Glob::Recursive => {
                    let re = $part.re("/");
                    for m in $expected_matches {
                        check!(re.is_match(m), "matching {m:?} against {}", $part.re_string("/"));
                    }
                }
                other => panic!("Expected Recursive, got {:?}", other),
            }
        };
        ($part:expr, Recursive) => {{
            let em: &[&str] = &[];
            assert_scanner_part!($part, Recursive, em);
        }};
        // convenience rule for testing one-choice patterns
        ($part:expr, OneChoice($expected:expr)) => {
            match $part {
                Glob::Choice{ allowed, .. } => {
                    assert!(allowed.len() == 1);
                    assert!(allowed[0] == $expected);
                },
                other => panic!("Got {:?}, expected Choice([{:?}])", other, $expected),
            }
        };
        ($part:expr, Choice($expected:expr), $expected_matches:expr, !$expected_does_not_match:expr) => {
            match $part {
                Glob::Choice { allowed, .. } => {
                    check!(*allowed == $expected);
                    assert_scanner_part!(@test_matches, $part.re("/"), $expected_matches, !$expected_does_not_match);
                }
                other => panic!("Expected Choice({:?}), got {:?}", $expected, other),
            }
        };
        ($part:expr, Choice($expected:expr)) => {{
            let em: &[&str] = &[];
            let ednm: &[&str] = &[];
            assert_scanner_part!($part, Choice($expected), em, !ednm);
        }};
    }
}
